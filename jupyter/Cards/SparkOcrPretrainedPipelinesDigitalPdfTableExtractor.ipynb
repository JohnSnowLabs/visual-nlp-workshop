{"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"id":"cw8TvgGpEueR"},"id":"cw8TvgGpEueR"},{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-ocr-workshop/tree/master/jupyter/Cards/SparkOcrPretrainedPipelinesImageHandwrittenTransformerExtraction.ipynb)"],"metadata":{"id":"ZDTrYiFMEvbc"},"id":"ZDTrYiFMEvbc"},{"cell_type":"markdown","metadata":{"id":"lS_nUbuJKS-S"},"source":["# Example of Pretrained Pipelines\n","\n","Pretrained Pipelines can be considered predefined recipes in the form of Visual NLP pipelines, these recipes come with a set of stages and parameters that help to accomplish specific tasks.\n","\n","## Blogposts and videos\n","\n","- [Text Detection in Spark OCR](https://medium.com/spark-nlp/text-detection-in-spark-ocr-dcd8002bdc97)\n","\n","- [Table Detection & Extraction in Spark OCR](https://medium.com/spark-nlp/table-detection-extraction-in-spark-ocr-50765c6cedc9)\n","\n","- [Extract Tabular Data from PDF in Spark OCR](https://medium.com/spark-nlp/extract-tabular-data-from-pdf-in-spark-ocr-b02136bc0fcb)\n","\n","- [Signature Detection in Spark OCR](https://medium.com/spark-nlp/signature-detection-in-spark-ocr-32f9e6f91e3c)\n","\n","- [GPU image pre-processing in Spark OCR](https://medium.com/spark-nlp/gpu-image-pre-processing-in-spark-ocr-3-1-0-6fc27560a9bb)\n","\n","- [How to Setup Spark OCR on UBUNTU - Video](https://www.youtube.com/watch?v=cmt4WIcL0nI)\n","\n","\n","**More examples here**\n","\n","https://github.com/JohnSnowLabs/spark-ocr-workshop"],"id":"lS_nUbuJKS-S"},{"cell_type":"markdown","source":["### Colab Setup"],"metadata":{"id":"Zg7TmGnpEGiX"},"id":"Zg7TmGnpEGiX"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"elapsed":11201,"status":"ok","timestamp":1723022203191,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"},"user_tz":-120},"id":"p-XWPpzsgAf_","outputId":"c234de4c-c986-4bb1-a226-fdc4da95c775"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f4ef2625-c5c0-4603-8e9d-91500d81ae17\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f4ef2625-c5c0-4603-8e9d-91500d81ae17\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving spark_nlp_for_healthcare_spark_ocr_9387.json to spark_nlp_for_healthcare_spark_ocr_9387.json\n"]}],"source":["import json, os\n","import sys\n","\n","if 'google.colab' in sys.modules:\n","    from google.colab import files\n","\n","    if 'spark_ocr.json' not in os.listdir():\n","      license_keys = files.upload()\n","      os.rename(list(license_keys.keys())[0], 'spark_ocr.json')\n","\n","with open('spark_ocr.json') as f:\n","    license_keys = json.load(f)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)"],"id":"p-XWPpzsgAf_"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":198390,"status":"ok","timestamp":1723022401577,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"},"user_tz":-120},"id":"8MNJwieTgEYq","outputId":"f560e4b3-f30a-4d05-ac32-7976967a8030"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.2/579.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/5.4.0-f40a4114fd59c8d06434c58c9e28fa076aa4af9e\n","Collecting spark-ocr==5.4.0\n","  Downloading https://pypi.johnsnowlabs.com/5.4.0-f40a4114fd59c8d06434c58c9e28fa076aa4af9e/spark-ocr/spark-ocr-5.4.0.tar.gz (42.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting fuzzywuzzy==0.18.0 (from spark-ocr==5.4.0)\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n","Collecting torchvision<0.15.0,>=0.7.0 (from spark-ocr==5.4.0)\n","  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n","Collecting numpy<=1.24.3,>=1.21.6 (from spark-ocr==5.4.0)\n","  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Requirement already satisfied: pillow<=10.0.0,>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.4.0) (9.4.0)\n","Requirement already satisfied: py4j>=0.10.9 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.4.0) (0.10.9.3)\n","Requirement already satisfied: pyspark<=3.5.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.4.0) (3.2.1)\n","Collecting scikit-image<=0.22.0,>=0.18.1 (from spark-ocr==5.4.0)\n","  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting implicits==1.0.2 (from spark-ocr==5.4.0)\n","  Downloading implicits-1.0.2-py3-none-any.whl.metadata (2.7 kB)\n","Collecting craft-text-detector==0.4.2 (from spark-ocr==5.4.0)\n","  Downloading craft_text_detector-0.4.2-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: spark-nlp==5.4.0 in /usr/local/lib/python3.10/dist-packages (from spark-ocr==5.4.0) (5.4.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector==0.4.2->spark-ocr==5.4.0) (2.3.1+cu121)\n","Collecting opencv-python<4.5.4.62,>=3.4.8.29 (from craft-text-detector==0.4.2->spark-ocr==5.4.0)\n","  Downloading opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector==0.4.2->spark-ocr==5.4.0) (1.13.1)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from craft-text-detector==0.4.2->spark-ocr==5.4.0) (5.1.0)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.4.0) (3.3)\n","Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.4.0) (2.34.2)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.4.0) (2024.7.24)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.4.0) (24.1)\n","Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image<=0.22.0,>=0.18.1->spark-ocr==5.4.0) (0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision<0.15.0,>=0.7.0->spark-ocr==5.4.0) (4.12.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision<0.15.0,>=0.7.0->spark-ocr==5.4.0) (2.31.0)\n","Collecting torch>=1.6.0 (from craft-text-detector==0.4.2->spark-ocr==5.4.0)\n","  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.4.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.4.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.4.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.4.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.4.0) (71.0.4)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->craft-text-detector==0.4.2->spark-ocr==5.4.0) (0.43.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.4.0) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.4.0) (3.15.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.4.0) (4.66.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.4.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.4.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.4.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision<0.15.0,>=0.7.0->spark-ocr==5.4.0) (2024.7.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.4.0) (2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==5.4.0) (1.7.1)\n","Downloading craft_text_detector-0.4.2-py3-none-any.whl (18 kB)\n","Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Downloading implicits-1.0.2-py3-none-any.whl (3.7 kB)\n","Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m787.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: spark-ocr\n","  Building wheel for spark-ocr (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for spark-ocr: filename=spark_ocr-5.4.0-py3-none-any.whl size=42724101 sha256=704d81f3bbc13a4bb9d78643191d24a06a07499c0e42486399d953150cc4d9df\n","  Stored in directory: /root/.cache/pip/wheels/58/9a/fe/ced6dcf53af9151dc754685171b94bda4de017f239559033d6\n","Successfully built spark-ocr\n","Installing collected packages: implicits, fuzzywuzzy, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, opencv-python, nvidia-cudnn-cu11, torch, scikit-image, torchvision, craft-text-detector, spark-ocr\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.10.0.84\n","    Uninstalling opencv-python-4.10.0.84:\n","      Successfully uninstalled opencv-python-4.10.0.84\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.1+cu121\n","    Uninstalling torch-2.3.1+cu121:\n","      Successfully uninstalled torch-2.3.1+cu121\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.23.2\n","    Uninstalling scikit-image-0.23.2:\n","      Successfully uninstalled scikit-image-0.23.2\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.18.1+cu121\n","    Uninstalling torchvision-0.18.1+cu121:\n","      Successfully uninstalled torchvision-0.18.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xgboost 2.1.1 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n","albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n","albumentations 1.4.12 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n","pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\n","torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 1.13.1 which is incompatible.\n","torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed craft-text-detector-0.4.2 fuzzywuzzy-0.18.0 implicits-1.0.2 numpy-1.24.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 opencv-python-4.5.4.60 scikit-image-0.22.0 spark-ocr-5.4.0 torch-1.13.1 torchvision-0.14.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"0370c9c0e0ad44d8a4c7133fdd54a0c6"}},"metadata":{}}],"source":["!pip install transformers\n","\n","# Installing pyspark and spark-nlp\n","%pip install --upgrade -q pyspark==3.2.1 spark-nlp==$PUBLIC_VERSION\n","\n","# Installing Spark OCR\n","#! pip uninstall spark-ocr -Y\n","%pip install spark-ocr==$OCR_VERSION --extra-index-url=https://pypi.johnsnowlabs.com/$SPARK_OCR_SECRET --upgrade"],"id":"8MNJwieTgEYq"},{"cell_type":"markdown","metadata":{"id":"2_pdaKeVNhPN"},"source":["<b><h1><font color='darkred'>!!! ATTENTION !!! </font><h1><b>\n","\n","<b>After running previous cell, <font color='darkred'>RESTART the COLAB RUNTIME </font> and go ahead.<b>"],"id":"2_pdaKeVNhPN"},{"cell_type":"markdown","source":["### Initialize Spark session"],"metadata":{"id":"n8ObGKZJEKuY"},"id":"n8ObGKZJEKuY"},{"cell_type":"code","execution_count":1,"metadata":{"id":"fAA0ayIXgH6g","executionInfo":{"status":"ok","timestamp":1723022667564,"user_tz":-120,"elapsed":367,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"}}},"outputs":[],"source":["import json, os\n","\n","with open(\"spark_ocr.json\", 'r') as f:\n","  license_keys = json.load(f)\n","\n","# Adding license key-value pairs to environment variables\n","os.environ.update(license_keys)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)"],"id":"fAA0ayIXgH6g"},{"cell_type":"code","execution_count":2,"metadata":{"id":"b2xXQVflgJzD","executionInfo":{"status":"ok","timestamp":1723022675270,"user_tz":-120,"elapsed":7465,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"}}},"outputs":[],"source":["import pkg_resources\n","\n","from pyspark.ml import PipelineModel\n","import pyspark.sql.functions as f\n","\n","from sparkocr import start\n","from sparkocr.transformers import *\n","from sparkocr.enums import *\n","from sparkocr.utils import *\n","from sparkocr.metrics import score"],"id":"b2xXQVflgJzD"},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":67356,"status":"ok","timestamp":1723022742624,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"},"user_tz":-120},"id":"ijb1K7YWgLZs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0767e93c-7062-4b1c-c5e4-bfac5cc9621c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark version: 3.2.1\n","Spark NLP version: 5.4.0\n","Spark OCR version: 5.4.0\n","\n"]}],"source":["# Start spark\n","spark = start(secret=SPARK_OCR_SECRET, nlp_version=PUBLIC_VERSION)"],"id":"ijb1K7YWgLZs"},{"cell_type":"markdown","metadata":{"id":"t-XtrWSDKS-X"},"source":["## Load Pretrained Pipelines\n"],"id":"t-XtrWSDKS-X"},{"cell_type":"code","execution_count":4,"id":"aabc3a5f-435c-4c56-92c7-c04a12820d68","metadata":{"id":"aabc3a5f-435c-4c56-92c7-c04a12820d68","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723022772903,"user_tz":-120,"elapsed":30282,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"}},"outputId":"4c981961-8105-48cf-d718-0fba7030a50a"},"outputs":[{"output_type":"stream","name":"stdout","text":["digital_pdf_table_extractor download started this may take some time.\n","Approx size to download 264.9 MB\n","[OK!]\n"]}],"source":["from sparknlp.pretrained import PretrainedPipeline\n","\n","pipeline = PretrainedPipeline('digital_pdf_table_extractor', 'en', 'clinical/ocr')"]},{"cell_type":"markdown","metadata":{"id":"RRlw0XvRKS-Y"},"source":["## Call the pipeline"],"id":"RRlw0XvRKS-Y"},{"cell_type":"code","execution_count":5,"id":"db97cde8-5855-4a1d-ad33-5e67522f95d3","metadata":{"id":"db97cde8-5855-4a1d-ad33-5e67522f95d3","executionInfo":{"status":"ok","timestamp":1723022846546,"user_tz":-120,"elapsed":73653,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"}},"colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"2ff98960-edd5-4013-b471-4d1d92482c57"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["+--------------------+--------------------+------+--------------------+----------------+---------------+-------+--------------------+-----------+-----------+-----------+--------------------+--------------------+---------+-----------+\n","|                path|    modificationTime|length|                hocr|height_dimension|width_dimension|pagenum|               image|total_pages|tmp_pagenum|documentnum|       table_regions|              tables|exception|table_index|\n","+--------------------+--------------------+------+--------------------+----------------+---------------+-------+--------------------+-----------+-----------+-----------+--------------------+--------------------+---------+-----------+\n","|file:/content/Bio...|2024-08-07 09:24:...| 54028|<div title=\"bbox ...|             841|            595|      0|{file:/content/Bi...|          1|          0|          0|{0, 0, 54.70161, ...|{{-1, -1, 54.7016...|     null|          0|\n","+--------------------+--------------------+------+--------------------+----------------+---------------+-------+--------------------+-----------+-----------+-----------+--------------------+--------------------+---------+-----------+"],"text/html":["<table border='1'>\n","<tr><th>path</th><th>modificationTime</th><th>length</th><th>hocr</th><th>height_dimension</th><th>width_dimension</th><th>pagenum</th><th>image</th><th>total_pages</th><th>tmp_pagenum</th><th>documentnum</th><th>table_regions</th><th>tables</th><th>exception</th><th>table_index</th></tr>\n","<tr><td>file:/content/Bio...</td><td>2024-08-07 09:24:...</td><td>54028</td><td>&lt;div title=&quot;bbox ...</td><td>841</td><td>595</td><td>0</td><td>{file:/content/Bi...</td><td>1</td><td>0</td><td>0</td><td>{0, 0, 54.70161, ...</td><td>{{-1, -1, 54.7016...</td><td>null</td><td>0</td></tr>\n","</table>\n"]},"metadata":{},"execution_count":5}],"source":["pdf_path = '/content/BiomedPap_bio-202402-0013-3.pdf'\n","pdf_example_df = spark.read.format(\"binaryFile\").load(pdf_path).cache()\n","result = pipeline.transform(pdf_example_df)\n","result"]},{"cell_type":"code","source":["display_images(result, \"image\", width=1000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VaWQ2nULJT8daXsCYGLzJ9iEbBCXQmJg"},"id":"-zGM8h_VZzk9","executionInfo":{"status":"ok","timestamp":1723022875647,"user_tz":-120,"elapsed":29104,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"}},"outputId":"d29471d5-f27c-4b13-fbb2-d350e96c04cb"},"id":"-zGM8h_VZzk9","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["display_tables(result, table_col = \"tables\", table_index_col = \"table_index\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"speA0VtXaPE4","executionInfo":{"status":"ok","timestamp":1723022900503,"user_tz":-120,"elapsed":24858,"user":{"displayName":"Aymane Chilah","userId":"03881241080678771864"}},"outputId":"0c28d27d-12f8-4609-f6f7-b16b467b1eae"},"id":"speA0VtXaPE4","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Filename: BiomedPap_bio-202402-0013-3.pdf\n","Page: 0\n","Table: 0\n","Number of Columns: 3\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table><tr><th>col0</th><th>col1</th><th>col2</th></tr><tr><td>Empty</td><td>cTnI ( ng / L ) ( Architect , Abbott )</td><td>cTnT ( ng / L ) ( Cobas , Roche )</td></tr><tr><td>Case 1</td><td>Empty</td><td>Empty</td></tr><tr><td>First sample ( before hospitalisation )</td><td>1782</td><td>7</td></tr><tr><td>Samples during hospitalisation</td><td>1741 , 3520 and 3622</td><td>34 ( after coronary angiography )</td></tr><tr><td>After hospitalisation  </td><td>395 ( 3 years after hospitalisation ) 360 ( 4 years after hospitalisation ) 536 ( 5 years after hospitalisation )</td><td>  </td></tr><tr><td>Case 2</td><td>Empty</td><td>Empty</td></tr><tr><td>June 25</td><td>107</td><td>–</td></tr><tr><td>July 2</td><td>835</td><td>–</td></tr><tr><td>July 28</td><td>–</td><td>8</td></tr><tr><td>August 25</td><td>439</td><td>Empty</td></tr><tr><td>October 21</td><td>96</td><td>6</td></tr></table>"]},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}