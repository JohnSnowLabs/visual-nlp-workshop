{"cells":[{"cell_type":"markdown","id":"843283de-d34a-434a-9fae-e6729d3ffd23","metadata":{"id":"843283de-d34a-434a-9fae-e6729d3ffd23"},"source":["# De-identification Dicom documents with encapsulated Pdf document"]},{"cell_type":"markdown","id":"e4c95142","metadata":{"id":"e4c95142"},"source":["## Install spark-ocr python packge\n","Need specify:\n","- license\n","- path to `spark-ocr-assembly-[version].jar` and `spark-nlp-jsl-[version]`\n","- or `secret` for Spark OCR and `nlp_secret` for Spark NLP Internal\n","- `aws_access_key` and `aws_secret_key`for download pretrained models\n","\n","For more details about Dicom de-identification please read:\n","\n"," - [DICOM de-identification at scale in Visual NLP — Part 1.](https://medium.com/john-snow-labs/dicom-de-identification-at-scale-in-visual-nlp-part-1-68784177f5f0)\n","\n"," - [DICOM de-identification at scale in Visual NLP — Part 2.](https://medium.com/john-snow-labs/dicom-de-identification-at-scale-in-visual-nlp-part-2-361af5e36412)\n","\n"," - [DICOM de-identification at scale in Visual NLP — Part 3.](https://medium.com/john-snow-labs/dicom-de-identification-at-scale-in-visual-nlp-part-3-ac750be386cb)"]},{"cell_type":"code","execution_count":null,"id":"61b16a4a-138f-4d7d-bb6b-b15a6e5ccb89","metadata":{"id":"61b16a4a-138f-4d7d-bb6b-b15a6e5ccb89"},"outputs":[],"source":["license = \"\"\n","secret = \"\"\n","nlp_secret = \"\"\n","aws_access_key = \"\"\n","aws_secret_key = \"\"\n","\n","version = secret.split(\"-\")[0]\n","spark_ocr_jar_path = \"../../../target/scala-2.12\""]},{"cell_type":"markdown","id":"4e662872-2e3d-4dbf-951b-ae363be3dcf9","metadata":{"id":"4e662872-2e3d-4dbf-951b-ae363be3dcf9"},"source":["## Install requirements"]},{"cell_type":"code","execution_count":null,"id":"0b674f64-0058-49b1-8f54-04ba92c419de","metadata":{"id":"0b674f64-0058-49b1-8f54-04ba92c419de"},"outputs":[],"source":["# NBVAL_SKIP\n","%pip install --upgrade spark-nlp-jsl==5.1.1  --extra-index-url https://pypi.johnsnowlabs.com/$nlp_secret\n","%pip install spark-nlp==5.1.1\n","%pip install spark-ocr==$version --extra-index-url=https://pypi.johnsnowlabs.com/$secret --upgrade\n","%pip install pydicom highdicom\n","%pip install pillow-jpls"]},{"cell_type":"markdown","id":"64f3b25b-a5d5-4cba-bcac-3ac8db699eec","metadata":{"id":"64f3b25b-a5d5-4cba-bcac-3ac8db699eec"},"source":["## Start Spark session"]},{"cell_type":"code","execution_count":null,"id":"6a1aca55-7435-46d2-844f-780023c35f63","metadata":{"id":"6a1aca55-7435-46d2-844f-780023c35f63"},"outputs":[],"source":["from sparkocr import start\n","import os\n","from pyspark import SparkConf\n","\n","if license:\n","    os.environ['JSL_OCR_LICENSE'] = license\n","    os.environ['SPARK_NLP_LICENSE'] = license\n","\n","if aws_access_key:\n","    os.environ['AWS_ACCESS_KEY'] = aws_access_key\n","    os.environ['AWS_SECRET_ACCESS_KEY'] = aws_secret_key\n","\n","\n","spark = start(secret=secret,\n","              nlp_secret=nlp_secret,\n","              jar_path=spark_ocr_jar_path,\n","              nlp_internal=\"5.3.0\")\n","\n","spark"]},{"cell_type":"markdown","id":"c383814d-51cf-4bcb-b3f8-2c5baf084968","metadata":{"id":"c383814d-51cf-4bcb-b3f8-2c5baf084968"},"source":["## Import transformers and annotators"]},{"cell_type":"code","execution_count":null,"id":"eb0a451a-6b20-4281-b40a-837048ced908","metadata":{"id":"eb0a451a-6b20-4281-b40a-837048ced908","outputId":"cccc7747-9662-43c0-a9cb-5f89fc26d514"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark NLP version: 5.1.2\n","Spark NLP internal version: 5.1.1\n","Spark OCR version: 5.1.0\n"]}],"source":["import os\n","import sys\n","\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","import sparknlp_jsl\n","from sparknlp_jsl.annotator import *\n","\n","import sparkocr\n","from sparkocr.transformers import *\n","from sparkocr.utils import *\n","from sparkocr.enums import *\n","from sparkocr.schemas import BinarySchema\n","\n","from pyspark.ml import PipelineModel, Pipeline\n","from pyspark.sql.functions import *\n","\n","import pillow-jpls\n","\n","print(f\"Spark NLP version: {sparknlp.version()}\")\n","print(f\"Spark NLP internal version: {sparknlp_jsl.version()}\")\n","print(f\"Spark OCR version: {sparkocr.version()}\")"]},{"cell_type":"markdown","id":"7fe452f1-df0d-489a-865a-85912ef721a2","metadata":{"id":"7fe452f1-df0d-489a-865a-85912ef721a2"},"source":["## Define Spark NLP pipeline for de-identification text"]},{"cell_type":"code","execution_count":null,"id":"b9de8226-5864-48e4-aeca-fc002ba29983","metadata":{"id":"b9de8226-5864-48e4-aeca-fc002ba29983"},"outputs":[],"source":["def deidentification_nlp_pipeline(input_column, prefix = \"\", model=\"ner_deid_large\"):\n","    document_assembler = DocumentAssembler() \\\n","        .setInputCol(input_column) \\\n","        .setOutputCol(prefix + \"document_raw\")\n","\n","    cleanUpPatterns = [\"<[^>]*>\", \":\"]\n","    documentNormalizer = DocumentNormalizer() \\\n","      .setInputCols(prefix + \"document_raw\") \\\n","      .setOutputCol(prefix + \"document\") \\\n","      .setAction(\"clean\") \\\n","      .setPatterns(cleanUpPatterns) \\\n","      .setReplacement(\" \") \\\n","      .setPolicy(\"pretty_all\")\n","\n","    # Sentence Detector annotator, processes various sentences per line\n","    sentence_detector = SentenceDetector() \\\n","        .setInputCols([prefix + \"document\"]) \\\n","        .setOutputCol(prefix + \"sentence\")\n","\n","    tokenizer = Tokenizer() \\\n","        .setInputCols([prefix + \"sentence\"]) \\\n","        .setOutputCol(prefix + \"token\")\n","\n","    # Clinical word embeddings\n","    word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n","        .setInputCols([prefix + \"sentence\", prefix + \"token\"]) \\\n","        .setOutputCol(prefix + \"embeddings\") \\\n","        .setEnableInMemoryStorage(True)\n","\n","    clinical_ner = MedicalNerModel.pretrained(model, \"en\", \"clinical/models\") \\\n","        .setInputCols([prefix + \"sentence\", prefix + \"token\", prefix + \"embeddings\"]) \\\n","        .setOutputCol(prefix + \"ner\")\n","\n","    custom_ner_converter = NerConverter() \\\n","        .setInputCols([prefix + \"sentence\", prefix + \"token\", prefix + \"ner\"]) \\\n","        .setOutputCol(prefix + \"ner_chunk\") \\\n","        .setWhiteList(['NAME', 'AGE', 'CONTACT', 'ID',\n","                   'LOCATION', 'PROFESSION', 'PERSON', 'DATE', 'DOCTOR'])\n","\n","    nlp_pipeline = Pipeline(stages=[\n","            document_assembler,\n","            documentNormalizer,\n","            sentence_detector,\n","            tokenizer,\n","            word_embeddings,\n","            clinical_ner,\n","            custom_ner_converter\n","        ])\n","    empty_data = spark.createDataFrame([[\"\"]]).toDF(input_column)\n","    nlp_model = nlp_pipeline.fit(empty_data)\n","    return nlp_model"]},{"cell_type":"markdown","id":"03817e0d-7b17-423b-ba52-1ed625cf4a75","metadata":{"id":"03817e0d-7b17-423b-ba52-1ed625cf4a75"},"source":["## Define Spark Ocr pipeline"]},{"cell_type":"code","execution_count":null,"id":"fd8baf07-8ced-4671-af56-6e228d0aa022","metadata":{"id":"fd8baf07-8ced-4671-af56-6e228d0aa022","outputId":"8e2022ea-e532-4afd-c7f9-b83ba1f8fabe"},"outputs":[{"name":"stdout","output_type":"stream","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_deid_generic_augmented download started this may take some time.\n","[OK!]\n"]}],"source":["# Extract encapsulated Pdf from the Dicom\n","dicom_to_pdf = DicomToPdf() \\\n","    .setInputCols([\"path\"]) \\\n","    .setOutputCol(\"pdf\") \\\n","    .setKeepInput(True)\n","\n","# Convert Pdf to the image\n","pdf_to_image = PdfToImage() \\\n","    .setInputCol(\"pdf\") \\\n","    .setOutputCol(\"image\") \\\n","    .setFallBackCol(\"text_image\")\n","\n","# Recognize text\n","ocr = ImageToText() \\\n","    .setInputCol(\"image\") \\\n","    .setOutputCol(\"text\") \\\n","    .setIgnoreResolution(False) \\\n","    .setPageIteratorLevel(PageIteratorLevel.SYMBOL) \\\n","    .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) \\\n","    .setConfidenceThreshold(70)\n","\n","# Found coordinates of sensitive data\n","position_finder = PositionFinder() \\\n","    .setInputCols(\"ner_chunk\") \\\n","    .setOutputCol(\"regions\") \\\n","    .setPageMatrixCol(\"positions\") \\\n","    .setOcrScaleFactor(1)\n","\n","# Hide sensitive data\n","drawRegions = ImageDrawRegions()  \\\n","    .setInputCol(\"image\")  \\\n","    .setInputRegionsCol(\"regions\")  \\\n","    .setOutputCol(\"image_with_regions\")  \\\n","    .setFilledRect(True) \\\n","    .setRectColor(Color.gray)\n","\n","# Convert image to Pdf\n","image_to_pdf = ImageToPdf() \\\n","    .setInputCol(\"image_with_regions\") \\\n","    .setOutputCol(\"pdf\")\n","\n","# Update Pdf in Dicom\n","dciom_update_pdf = DicomUpdatePdf() \\\n","    .setInputCol(\"path\") \\\n","    .setInputPdfCol(\"pdf\") \\\n","    .setOutputCol(\"dicom\") \\\n","    .setKeepInput(True)\n","\n","# Deidentify metadata in Dicom\n","dicom_deidentifier = DicomMetadataDeidentifier() \\\n","    .setInputCols([\"dicom\"]) \\\n","    .setOutputCol(\"dicom_cleaned\")\n","\n","# OCR pipeline\n","pipeline = PipelineModel(stages=[\n","     dicom_to_pdf,\n","     pdf_to_image,\n","     ocr,\n","     deidentification_nlp_pipeline(input_column=\"text\", prefix=\"\", model=\"ner_deid_generic_augmented\"),\n","     position_finder,\n","     drawRegions,\n","     image_to_pdf,\n","     dciom_update_pdf,\n","     dicom_deidentifier\n","])"]},{"cell_type":"markdown","id":"de0960ab-c815-460a-bd2d-705a91d494e7","metadata":{"id":"de0960ab-c815-460a-bd2d-705a91d494e7"},"source":["## Read dicom files"]},{"cell_type":"code","execution_count":null,"id":"d53c3eee-8649-44c9-b3b8-cacc3c36447c","metadata":{"id":"d53c3eee-8649-44c9-b3b8-cacc3c36447c"},"outputs":[],"source":["dicom_path = './../data/dicom/encapsulated/*.dcm'\n","dicom_df = spark.read.format(\"binaryFile\").load(dicom_path)"]},{"cell_type":"markdown","id":"ed70cd1b-78bf-4bdf-93e5-2e344ab2f03b","metadata":{"id":"ed70cd1b-78bf-4bdf-93e5-2e344ab2f03b"},"source":["## Run pipeline and store resulst"]},{"cell_type":"code","execution_count":null,"id":"b843cc7d-5f10-4c6d-af2c-6786e297da54","metadata":{"id":"b843cc7d-5f10-4c6d-af2c-6786e297da54"},"outputs":[],"source":["output_path = \"./deidentified_pdf/\"\n","\n","def get_name(path, keep_subfolder_level=0):\n","    path = path.split(\"/\")\n","    path[-1] = \".\".join(path[-1].split('.')[:-1])\n","    return \"/\".join(path[-keep_subfolder_level-1:])\n","\n","result = pipeline.transform(dicom_df)\n","result.withColumn(\"fileName\", udf(get_name, StringType())(col(\"path\"))) \\\n","    .write \\\n","    .format(\"binaryFormat\") \\\n","    .option(\"type\", \"dicom\") \\\n","    .option(\"field\", \"dicom_cleaned\") \\\n","    .option(\"prefix\", \"\") \\\n","    .option(\"nameField\", \"fileName\") \\\n","    .mode(\"overwrite\") \\\n","    .save(output_path)"]},{"cell_type":"markdown","id":"f91ca07a","metadata":{"id":"f91ca07a"},"source":["## Remove results"]},{"cell_type":"code","execution_count":null,"id":"458c1876","metadata":{"id":"458c1876"},"outputs":[],"source":["%%bash\n","rm -r -f ./deidentified_pdf"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[{"file_id":"https://github.com/JohnSnowLabs/visual-nlp-workshop/blob/master/jupyter/Dicom/SparkOcrDeidentificationDicomWithEncapsulatedPDF.ipynb","timestamp":1729206365205}]}},"nbformat":4,"nbformat_minor":5}